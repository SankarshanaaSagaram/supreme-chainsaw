{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:12:45.092142Z","iopub.execute_input":"2023-03-15T17:12:45.093238Z","iopub.status.idle":"2023-03-15T17:12:45.132923Z","shell.execute_reply.started":"2023-03-15T17:12:45.093186Z","shell.execute_reply":"2023-03-15T17:12:45.131540Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mnist-in-csv/mnist_test.csv\n/kaggle/input/mnist-in-csv/mnist_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#core pytorch functionality\nimport torch\n#building blocks for neural networks - layers , activation functions, loss functions,etc.\nimport torch.nn as nn\n#functional versions of neural network components(activations)\nimport torch.nn.functional as F\n##data loaders,samplers,datasets\nimport torch.utils.data\n#provides automatic differentiation for backpropogation\nfrom torch.autograd import Variable\n#optimization algorithms - stochastic gradient descent , adam\nfrom torch.optim import Adam\n#functions for measuring time and measring code execution\nimport time\n#splitting data into training and validation sets\nfrom torch.utils.data import random_split\nimport matplotlib.pyplot as plt\nfrom torchvision.datasets import MNIST\n#converts numpy array to pytorch tensor\nfrom torchvision.transforms import ToTensor\n#flattens tensor into 1D tensor\nfrom torch import flatten\n#splitting data into training and test sets\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:12:45.136552Z","iopub.execute_input":"2023-03-15T17:12:45.137613Z","iopub.status.idle":"2023-03-15T17:12:49.027752Z","shell.execute_reply.started":"2023-03-15T17:12:45.137570Z","shell.execute_reply":"2023-03-15T17:12:49.026419Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"mnist_train = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\nmnist_test = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:12:49.029208Z","iopub.execute_input":"2023-03-15T17:12:49.029717Z","iopub.status.idle":"2023-03-15T17:12:55.781737Z","shell.execute_reply.started":"2023-03-15T17:12:49.029676Z","shell.execute_reply":"2023-03-15T17:12:55.780426Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"y_train,x_train = mnist_train['label'].values, mnist_train.iloc[:,1:].values\ny_test,x_test = mnist_test['label'].values,mnist_test.iloc[:,1:].values","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:12:55.784754Z","iopub.execute_input":"2023-03-15T17:12:55.785926Z","iopub.status.idle":"2023-03-15T17:12:55.796802Z","shell.execute_reply.started":"2023-03-15T17:12:55.785885Z","shell.execute_reply":"2023-03-15T17:12:55.795704Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"INIT_LR = 1e-3\nBATCH_SIZE = 32\nEPOCHS = 10\nTRAIN_SPLIT = 0.80\nVAL_SPLIT = 0.2\ndevice = torch.device('cuda'if torch.cuda.is_available() else 'cpu')\n\ntorch_X_train = torch.from_numpy(x_train).type(torch.LongTensor)\ntorch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\nprint(torch_X_train.shape)\n# create feature and targets tensor for test set.\ntorch_X_test = torch.from_numpy(x_test).type(torch.LongTensor)\ntorch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n\n# Pytorch train and test sets (tensor objects)\ntrain = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\ntest = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n\nnumTrainSamples = int(len(train)*TRAIN_SPLIT)\nnumValSamples = int(len(train)*VAL_SPLIT)\n(trainData,valData) = random_split(train,[numTrainSamples,numValSamples])\n\n# data loader object\ntrain_loader = torch.utils.data.DataLoader(trainData, batch_size = BATCH_SIZE, shuffle = False) #true?\nval_loader = torch.utils.data.DataLoader(valData, batch_size = BATCH_SIZE, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\nprint(train_loader)\n#calculkate steps per epcoh for training and validation set\ntrainSteps = len(train_loader.dataset)\nvalSteps = len(val_loader.dataset)\nprint('Training steps:',trainSteps)\nprint('Validation steps: ', valSteps)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:12:55.798597Z","iopub.execute_input":"2023-03-15T17:12:55.799038Z","iopub.status.idle":"2023-03-15T17:12:55.848157Z","shell.execute_reply.started":"2023-03-15T17:12:55.798959Z","shell.execute_reply":"2023-03-15T17:12:55.846987Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"torch.Size([60000, 784])\n<torch.utils.data.dataloader.DataLoader object at 0x7f7618ee1b90>\nTraining steps: 48000\nValidation steps:  12000\n","output_type":"stream"}]},{"cell_type":"code","source":"class LeNet(nn.Module):\n    def __init__(self,numChannels,classes):\n        #call the parent constructor\n        super(LeNet,self).__init__()\n        #initialise first set of convolutions\n        self.conv1 = nn.Conv2d(in_channels = numChannels, out_channels = 20,kernel_size = (5,5))\n        self.relu1 = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(kernel_size = (2,2),stride = (2,2))\n        \n        #initialise second set of convolutions\n        \n        self.conv2 = nn.Conv2d(in_channels = 20,out_channels = 50,kernel_size = (5,5))\n        self.relu2 = nn.ReLU()\n        self.maxpool2 = nn.MaxPool2d(kernel_size = (2,2),stride = (2,2))\n        \n        #initialise first set of FC \n        self.fc1 = nn.Linear(in_features = 800,out_features = 500)\n        self.relu3 = nn.ReLU()\n        \n        #initialise softmax classifier\n        self.fc2 = nn.Linear(in_features=500,out_features = classes)\n        self.logSoftmax = nn.LogSoftmax(dim = 1)\n    def forward(self,x):\n        x = x.to(torch.float)\n        x = x.view(32,1,28,28)\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n    \n    # pass the output from the previous layer through the second\n    # set of CONV => RELU => POOL layers\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.maxpool2(x)\n    \n    # flatten the output from the previous layer and pass it\n    # through our only set of FC => RELU layers\n        x = flatten(x, 1)\n        x = self.fc1(x)\n        x = self.relu3(x)\n    \n    # pass the output to our softmax classifier to get our output\n    # predictions\n        x = self.fc2(x)\n        output = self.logSoftmax(x)\n    \n    # return the output predictions\n        return output\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:12:55.849401Z","iopub.execute_input":"2023-03-15T17:12:55.850014Z","iopub.status.idle":"2023-03-15T17:12:55.864663Z","shell.execute_reply.started":"2023-03-15T17:12:55.849956Z","shell.execute_reply":"2023-03-15T17:12:55.863401Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print('Initialising the lenet model')\nmodel = LeNet(numChannels = 1,classes=10)\nprint(type(model))\n#initialising optimizer and loss function\nopt = Adam(model.parameters(),lr = INIT_LR)\nprint(model.parameters())\n# cross entropy loss\nlossFn = nn.NLLLoss()\n#initialising a dictionary to store training history\nH = {\"train_loss\":[],\n    \"train_acc\":[],\n    \"val_loss\":[],\n    \"val_acc\":[]\n    }\nprint('training the network')\n# starting out timer\nstartTime = time.time()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:12:55.866742Z","iopub.execute_input":"2023-03-15T17:12:55.867134Z","iopub.status.idle":"2023-03-15T17:12:55.899804Z","shell.execute_reply.started":"2023-03-15T17:12:55.867098Z","shell.execute_reply":"2023-03-15T17:12:55.898076Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Initialising the lenet model\n<class '__main__.LeNet'>\n<generator object Module.parameters at 0x7f7618f588d0>\ntraining the network\n","output_type":"stream"}]},{"cell_type":"code","source":"for e in range(EPOCHS):\n    model.train()\n    totalTrainLoss = 0\n    totalValLoss = 0\n    trainCorrect = 0\n    valCorrect = 0\n    for(x,y) in train_loader:\n        (x,y) = (x.to(device),y.to(device))\n        # forward pass\n        pred = model(x)\n        loss = lossFn(pred,y)\n        # zero out the gradients, perform backpropagation and update weights\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n        # add loss to total training losss\n        # calculate the number of correct predictions\n        totalTrainLoss = totalTrainLoss + loss\n        trainCorrect = trainCorrect + (pred.argmax(1)==y).type(torch.float).sum().item()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:12:55.901466Z","iopub.execute_input":"2023-03-15T17:12:55.901808Z","iopub.status.idle":"2023-03-15T17:17:18.747705Z","shell.execute_reply.started":"2023-03-15T17:12:55.901776Z","shell.execute_reply":"2023-03-15T17:17:18.746355Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad(): # used to evaluate validation set, hence gradients not computed or updated in this dataset\n    model.eval()     # model put into evaluation mode - diables dropout and batch normalization\n    for (x,y) in val_loader:  #input data moved to device , loss calculated by applying loss function to predictions\n        (x,y) = (x.to(device),y.to(device))\n        pred = model(x)\n        totalValLoss = totalValLoss + lossFn(pred,y)\n        valCorrect += (pred.argmax(1)==y).type(torch.float).sum().item()   #valcorrect used to keep mtrack of correct predictions","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:17:18.749136Z","iopub.execute_input":"2023-03-15T17:17:18.750031Z","iopub.status.idle":"2023-03-15T17:17:20.419561Z","shell.execute_reply.started":"2023-03-15T17:17:18.749963Z","shell.execute_reply":"2023-03-15T17:17:20.418366Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"avgTrainLoss = totalTrainLoss / trainSteps\navgValLoss = totalValLoss / valSteps\n# calculate the training and validation accuracy\ntrainCorrect = trainCorrect / len(train_loader.dataset)\nvalCorrect = valCorrect / len(val_loader.dataset)\n# update our training history by appending to 'H' dictionary\nH[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\nH[\"train_acc\"].append(trainCorrect)\nH[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\nH[\"val_acc\"].append(valCorrect)\n# print the model training and validation information\nprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\nprint(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, trainCorrect))\nprint(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(avgValLoss, valCorrect))","metadata":{"execution":{"iopub.status.busy":"2023-03-15T17:17:20.422837Z","iopub.execute_input":"2023-03-15T17:17:20.423193Z","iopub.status.idle":"2023-03-15T17:17:20.433138Z","shell.execute_reply.started":"2023-03-15T17:17:20.423159Z","shell.execute_reply":"2023-03-15T17:17:20.431810Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[INFO] EPOCH: 10/10\nTrain loss: 0.001076, Train accuracy: 0.9919\nVal loss: 0.004125, Val accuracy: 0.9828\n\n","output_type":"stream"}]}]}
